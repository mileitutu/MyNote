1.Spark master是如何使用zookeeper进行HA的，有哪些元数据保存在zookeeper？
  答：spark通过 spark.deploy.zookeeper.dir 来指定master元数据在zookeeper中的存储位置，这些数据包括worker driver executor application
  standby节点从zookeeper中获取元数据信息来恢复集群运行，才能继续对外提供服务，恢复前不能接受请求
  master切换需要注意2点：
        1.主备master切换过程中，application已经从集群中获取了资源，切换时不影响已经获得的资源，所以在运行时job本身的调度和处理与master没有关系
        2.master切换过程中唯一影响的是不能提交新的job：一方面不能提交新的application给集群，因为只有active master才能接受新的程序的提交请求另一方面，已经在运行的application也不能够因为action操作触发新的job的提交请请求


2.Spark master HA主从切换过程中不影响集群已有作业运行，为什么？
    答：这个说法是不对的，在切换过程中，对已有作业也不是完全不影响，已有作业在执行action算子后不能向集群提交新的job。刨除这个情况，application在运行之前已经向集群申请过资源了，所以不影响


3.spark master的HA如何配置？
    答：1.配置zookeeper
        2.修改spark_env.sh ，添加
        export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER                                   -Dspark.deploy.zookeeper.url=zk01:2181,zk02:2181,zk03:2181 -Dspark.deploy.zookeeper.dir=/spark"
        并将spark_env.sh发送到各个节点
        3.在某个master节点执行./start-all.sh ， 会在此处启动主master。 其他的master备节点，则执行./sbin/start-master.sh
        4.提交程序的时候指定master的时候，要制定三台master
        比如 ./spark-shell --master spark://master01:7077,master02:7077,master03:7077
    
4.driver的功能是什么？
    答：1.application的主进程，具有main函数，是程序的入口，有sparkContext实例
        2.driver生成sparkContext和DAGScheduler，负责向集群申请资源，向master注册信息，负责作业的调度，负责作业的解析，生成stage，调度task到executor上。