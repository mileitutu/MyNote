1.Spark master是如何使用zookeeper进行HA的，有哪些元数据保存在zookeeper？
  答：spark通过 spark.deploy.zookeeper.dir 来指定master元数据在zookeeper中的存储位置，这些数据包括worker driver executor application
  standby节点从zookeeper中获取元数据信息来恢复集群运行，才能继续对外提供服务，恢复前不能接受请求
  master切换需要注意2点：
        1.主备master切换过程中，application已经从集群中获取了资源，切换时不影响已经获得的资源，所以在运行时job本身的调度和处理与master没有关系
        2.master切换过程中唯一影响的是不能提交新的job：一方面不能提交新的application给集群，因为只有active master才能接受新的程序的提交请求另一方面，已经在运行的application也不能够因为action操作触发新的job的提交请请求


2.Spark master HA主从切换过程中不影响集群已有作业运行，为什么？
    答：这个说法是不对的，在切换过程中，对已有作业也不是完全不影响，已有作业在执行action算子后不能向集群提交新的job。刨除这个情况，application在运行之前已经向集群申请过资源了，所以不影响


3.spark master的HA如何配置？
    答：1.配置zookeeper
        2.修改spark_env.sh ，添加
        export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER                                   -Dspark.deploy.zookeeper.url=zk01:2181,zk02:2181,zk03:2181 -Dspark.deploy.zookeeper.dir=/spark"
        并将spark_env.sh发送到各个节点
        3.在某个master节点执行./start-all.sh ， 会在此处启动主master。 其他的master备节点，则执行./sbin/start-master.sh
        4.提交程序的时候指定master的时候，要制定三台master
        比如 ./spark-shell --master spark://master01:7077,master02:7077,master03:7077
    
4.driver的功能是什么？
    答：1.application的主进程，具有main函数，是程序的入口，有sparkContext实例
        2.driver生成sparkContext和DAGScheduler，负责向集群申请资源，向master注册信息，负责作业的调度，负责作业的解析，生成stage，调度task到executor上。

5.spark的有几种部署模式？
    1.本地模式
        将spark应用以多线程的方式直接在本地运行，调试用
            1.local：只启动一个executor
            2.local[k]:启动k个executor
            3.local[*]:启动跟cpu数目相同的executor
    2.spark standalone
        分布式部署集群，自带完整的服务，资源管理和任务监控是spark自己监控，这个模式也是其他模式的基础
        包含cluster和client两种运行模式，cluster适合生产，driver运行在集群子节点，具有容错功能，client适合调试，dirver运行在客户端
    3.spark on yarn
        分布式部署集群，资源和任务监控交给yarn，但是目前及支持粗粒度资源分配方式。
        包含cluster和client两种运行模式，cluster适合生产，driver运行在集群子节点，具有容错功能，client适合调试，dirver运行在客户端
    4.spark on mesos
        1.粗粒度模式：每个应用程序的运行环境由若干个executor和一个driver组成，每个application在运行前需要将环境中的资源全部申请好，运行过程中要一直占用着这些资源，即使不使用也占着，最后程序运行结束后，回收资源，这种模式浪费资源
        2.细粒度模式：类似于现在的云计算模式，按需分配
    
6.spark中的worker的作用是什么？
    答：管理当前节点的资源，内存，cpu的使用状况，接收master发送过来的资源分配指令，通过executorrunner启动程序分配任务，worker相当于包工头

7.spark为什么比MapReduce快？
    答：1.基于内存计算，减少低效的磁盘交互
        2.高效的调度算法，基于DAG
        3.容错机制linage

8.hadoop shuffle 和 spark shuffle 的异同？


9.spark有哪些组件？
    答:master-管理集群和节点，不参与计算
       worker-计算节点，进程本身不参与计算，和master汇报
       driver-运行程序的main方法，创建spark cont对象
       spark context-控制整个application的生命周期
       client：用户提交application的入口


10.cache和persist的区别，持久化级别
    答：memory only
        memory and disk
        memory 

    1.cache只有一个持久化级别memory onlycache调用了persist，persist可以根据情况设置其他的缓存级别
    2.executor执行的时候，内存默认60%做cache，40%做task操作

10.简述spark集群搭建步骤
    答：