在交互式用户访问行为大数据分析平台这个项目中
我主要完成的工作是：
   1.用户访问session分析模块
   2.页单跳转化率模块
   3.各区域热门商品统计
   4.广告点击流量实时统计
   5.
   6.性能调优
   7.troubleshooting
   8.数据倾斜
   测试时使用mockdata

   整个企业级大数据项目开发的流程：
   1.基础数据结构设计
   2.分析需求
   3.技术方案设计

   技术方案设计：针对手头上有的基础数据和PM提出来的需求，来进行技术方案的设计，就是设计出来整个项目的技术架构，关键的技术点，以及技术选型。

   本项目技术架构：前端+J2EE+Spark+MySQL
   J2EE平台接收到指定统计分析任务的需求后，调用底层封装了spark-submit的shell脚本，用shell脚本提交我们编写的spark作业
   spark作业获取使用者指定的筛选参数，运行作业逻辑，进行该模块的统计和分析
   spark作业统计和分析的结果写入mysql指定的表
   最后，J2EE平台通过前端以表格，图表形式，展示和查看mysql中存储的该统计分析任务的结果数据


1.用户访问session分析模块

    技术点：
        1.通过底层数据聚合，减少spark作业处理数据量，tishengspark作业性能
        2.自定义accumulator实现复杂分布式计算
        3.spark按时间比例抽取算法
        4.spark自定义key二次排序
        5.spark分组取topN算法
        6.通过spark各种功能，进行各种聚合，采样，排序，取TOPn的实现

    1.根据使用者的筛选条件，筛选出指定的一些用户（年龄，职业，城市）
    2.对这些用户在指定日期内发起的session，进行聚合统计，比如统计出访问时长在0-3s内的sesison
    3.按时间比例随机抽取session，比如统计出当天session总量，在统计出12:00-13:00的session总量，算比例，如果当天要抽取1000个session，用这个比例乘以1000，得出12:00-13:00要抽取的session数量，接着随机抽取session
    3.获取点击量，评论，转发前10的文章的信息
    4.获取点击，下载，评论的前10的商品信息
    5.获取top10商品种类的点击量排名前10的session
    
    session第一次进入，到离开，或者长时间没有做操作，session结束


    （1）按条件筛选session
    user_visit_action一行代表了用户的一个行为，如果不统一筛选粒度，那么就要全表扫描，量太大，会导致运行速度大幅度降低
    这个项目选择按照session粒度对原始数据进行聚合
    也就是用一些最基本的筛选条件从hive表中提取数据，按照session_id进行聚合，聚合后的一条记录，就是一个用户某个session指定时间内访问的记录，比如搜索过的关键词，点击品类id，session对应的user信息
    聚合过后，就是针对session粒度的数据了，按照使用者指定的筛选条件进行数据筛选，筛选出来符合条件的用session粒度的数据，就是想要的session

    （2）聚合统计
    spark作业是分布式的，在spark中要实现分布式安全累加操作，基本上只有一个最好的选择，就是accumulator变量，如果是基础的accumulator变量，会需要将近20-30个accumulator变量，，1-3s,4-6s...但是这样，会导致代码中充斥了大量的accumulator变量，导致维护复杂，在修改代码时，很可能会导致错误
    对于这种情况，应使用accumulator自定义计数，也就是用一个accumulator来计算所有指标

    （3）在符合条件的session中，按照时间比例随机抽取1000个session
    技术上，要综合运用spark的countbykey,groupbykey,maptopair等算子，来开发一个复杂的按照时间比例随机均匀采样抽取的算法

    （4）在符合条件的session中（也适用于商品），获取点击，评论和转发排名前10的文章id
    需要对每个文章的点击,评论,转发的数量都惊醒统计，然后，使用自定义key二次排序算法，实现所有文章，按照三个字段，依次排序，首先比较点击，相同比较评论，相同比较转发

    （5）对于排名前10的文章（也适用于商品），分别获取其点击次数排名前10的session
    使用spark的分组取topN算法实现，也就是排名前10的品类对应的数据，按照品类id进行分组，然后求出每组点击数量排名前10的session
