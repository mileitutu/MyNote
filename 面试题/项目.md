这是一个Spark技术开发的大数据统计分析平台

对网站、APP的各种用户行为（访问，评论，转发，下载，广告点击等）进行分析，辅助数据分析人员和PM分析热门文章和广告。
最终目的是，提升业绩。

本项目使用core sql streaming

本项目进行了，离线计算和实时计算业务的开发

实现了4个业务模块：
1.用户访问session分析（对用户访问session进行统计分析）
	聚合指标计算
	按时间比例抽取session
	获取每天点击、评论、转发前10的文章，这个功能应用在广告商品也可以，就是获取每天点击，下载，安装排名前10的应用，还有自有商城的，点击，下单，支付的品类的前10的session和点击量（updatestatebykey，累加变量，二次排序）
	目的：产品经理形象的看到各种条件下的用户行为及统计指标，从而对公司的产品设计及业务发展作出调整
	这个模块主要用spark core实现
	
2.页单跳转化率统计：计算关键页面之间的跳转转化率
页面切片算法
页面流匹配算法
目的：让PM看到各个关键页面之间的转化率，从而对网页布局，进行更好的优化设计
主要用spark core实现
	
3.热门商品离线统计：
每天统计出各个区域的top3热门商品
用oozie进行离线统计任务定时调度
用zippeline进行数据可视化报表展示。
目的：看到公司售卖商品的整体情况
主要用spark sql实现

4.广告流量实时统计：
该模块负责实时统计公司的广告流量，包括广告展示流量，和广告点击流量
实现动态黑名单机制，以及黑名单过滤
实现滑动窗口内的各个城市的广告展现流量和广告点击流量的统计
实现各个区域每个广告的点击流量实时统计
实现每个区域top3点击量的广告统计	
主要是用spark streaming实现	
	
	
	
	
	
	
	
	
	
2.页单跳转化率统计
3.热门商品离线统计
4.广告流量实时统计

要把性能调优，troubleshooting，及数据倾斜的解决展现出来

这个项目开发流程是什么？
需求分析
方案设计
数据设计
编码实现
测试
性能调优



离线日志采集
数据源：网站\APP，这个项目是nginx
面向大量用户，高并发的情况下用nginx来接收请求，数据将作为log存储起来，服务器每接受一个请求或者每执行一个业务逻辑，就往日志文件里打一条log

日志文件（预先设置格式），通常每天一份，多个web服务器会有多份日志

日志转移工具，crontab定时调度shell脚本进行转移，将当天所有日志数据，采集起来，进行合并和处理，作为一份日志文件转一个flume agent正在监控的目录中

（如何合并日志？）


flume agent启动后会实时监控linux上面的某一个目录，有新文件进来，就会走后续的channel和sink，sink都会被指为HDFS

HDFS中的原始日志数据，会经过数据清洗
HDFS中存储的是一份经过数据清洗的日志文件（MR），针对HDFS中的原始日志进行数据清洗，写入HDFS中的另一个文件

把HDFS中的清洗后的数据，导入到HIVE中的某个表中，这里使用动态分区，HIVE使用分区表，每个分区放一天的数据

数据仓库建模的ETL。ETL会将原始日志所在的一个表，转换为几十张，上百张表，这几十张，上百张表，就是数据仓库。

这个项目，是针对HIVE中的表，也就是经过 HIVE ETL或建立起来的数据仓库中的某些表来开发的



模块一：用户访问session分析模块
整个大数据分析平台的架构：前端+J2EE+SPARK+MYSQL
1.通过J2EE平台（前端）提交各种分析任务，指定各种筛选条件，比如年龄，职业，城市
2.J2EE平台（后端）接收到执行统计分析任务的请求后，调用封装了spark-submit的shell脚本，向集群提交spark作业
3.spark作业获取筛选参数，进行该模块的统计和分析
4.将统计分析结果写入mysql中，指定的表
5.报表展示


技能点：1.JDBC辅助类封装
		2.用户访问session聚合统计
		3.按时间比例随机抽取session
		4.获取点击，评论，转发次数排名前10的文章，广告，商品品类
		5.获取top10品类的点击次数最多的10个session
		6.性能调优
		7.troubleshooting
		8.数据倾斜

1个session里可能包含很多个action，比如点击、搜索、下单、支付
	
专门有ETL工程师对原始日志数据进行ETL，形成各种表结构，对原始log进行处理聚合操作

之所以使用MYSQL表是因为J2EE要实现快速的实时插入和查询


模块一中各个小计数点：
1.按条件筛选session
这个功能，最大的作用就是灵活，可以让使用者对感兴趣的用户群体，进行各种统计和分析，拿到的结果数据只是针对特殊用户群体的分析结果，而不是对所有用户进行分析的泛泛的分析结果。

2.统计出符合条件的session中，访问时长在1s~3s、4s~6s、7s~9s、10s~30s、30s~60s、1m~3m、3m~10m、10m~30m、30m以上各个范围内的session占比，访问步长在1~3、4~6、7~9、10~30、30~60、60以上各个范围内的session占比
这个功能可以让人从全局角度看到，符合某些条件的用户群体，使用产品的一些习惯，比如在产品中的停留时间，人们会在使用产品过程中访问多少页面

3.在符合条件的session中，按照比例随机抽取1000个session
比如今天产生了100万个session，比如0点-1点产生了1万个session，1万个session占总session的1/100，就是说这个小时要随机抽取session数量是1000 * 1/100，就是10个，也就是要从这1万个session里抽10个session
做随机抽取session就是要做到，观察样本的公平性


4.在符合条件的session中，获取点击，下单，支付的排名前10的品类，按照这三个属性进行排序，这涉及到二次排序和topN
这个功能很重要，让我们看到符合条件的用户最感兴趣的是什么，可以让PM明白，各种不同的用户的喜好

5.对于排名前10的品类，分别获取其点击次数排名前10的session
这个功能的作用是，让我们看到，对top10品类，最感兴趣的最典型的用户的session行为


1.为什么要按照session粒度进行聚合？
	1.因为要根据不同的条件进行筛选，所以筛选粒度是不统一的
	2.不统一筛选粒度就要对所有数据进行全量扫描，但是如果数据量太大，就会导致spark作业运行速度大幅度降低
为了解决这两个问题，要对原始数据进行聚合，按照session粒度进行聚合。
用一些基本的筛选条件从hive中提取数据，然后按照，session_id进行聚合，聚合后的一条记录，就是用户在session内的访问记录
聚合过后，针对session粒度，按照使用者指定的筛选条件，进行数据筛选，筛选出来符合条件的session粒度的数据，就是我们想要的session了

2.聚合统计
spark作业时分布式的，需要一个队全局的变量，进行累加操作
在spark中，要实现分布式安全的累加操作，只有一个最好的选择，Accumulator变量。但是如果是基础的累加变量，在统计1s~3s、4s~6s。。。。时，要维护好多个Accumulator变量，复杂，在修改时也容易出错。所以，使用自定义Accumulator计数，来实现复杂的分布式计算，也就是用一个Accumulator，来计算所有指标

3.在符合条件的session中，按照时间比例抽取1000个session
综合运用countbykey，groupbykey，maptopair等算子，来开发一个按时间比例随机均匀采样抽取的算法

4.在符合条件的session中，获取点击，下单，支付的排名前10的品类
需要对每个品类的点击、下单、支付数量，都进行计算，然后，使用spark的自定义key二次排序算法，来实现所有品类，按照三个字段，依次进行排序

5.对于排名前10的品类，分别获取其点击次数排名前10的session

这个模块掌握到的技术点：
1.通过底层数据聚合，来减少spark作业处理数据量，从而提升spark作业的性能，从而从根本上，提升spark性能
2.自定义Accumulator来实现复杂分布式计算的技术
3.spark按时间比例随机抽取算法
4.spark自定义key二次排序
5.spark分组取topN
6、通过Spark的各种功能和技术点，进行各种聚合、采样、排序、取TopN业务的实现


在进行完了数据调研，需求分析，设计技术实现方案后，要进行数据设计
1.根据数据调研环节看项目是否要针对其开发一些Hive ETL
2.要设计spark作业要保存结果数据的业务表结构，从而让J2EE使用业务表中的数据，来为使用者展示任务执行结果。

数据设计之后，就是一个漫长的环节，就是编码实现，coding阶段，每开发完一个环节，都要走后续的两个环节，本地测试，和生产环境测试。

DAO模式
业务逻辑在service组件里，在spark作业中，业务逻辑代码就是在我们的spark作业里面
不用DAO模式，数据库访问代码回合业务逻辑代码耦合，
实现DAO模式：1.DAO接口 2.DAO实现类

内部类，就是包含在外部类中的类，一种是静态内部类，一种是非静态内部类
静态内部类是属于外部类的类成员，是一种静态的成员，是属于类的
非静态内部类是属于外部类的实例对象的一个实例成员，也就是说非静态内部类不是属于外部类的，而是属于外部类的实例的，创建非静态内部类的实例后，非静态内部类实例，必须跟一个外部类的实例进行关联和寄存关系的。

创建静态内部类 new Lei.Instance() 
创建非静态内部类 new Lei().Instance()

通常为了方便，都会使用静态内部类

匿名内部类：在一个内部类，只创建一次，使用一次，以后就不再使用的情况下，

JavaBean：通常来说，会将一个JavaBean与数据库中的某个表一一对应起来，在执行增删改查操作的时候，都是面向javabean来操作的，field private ，共有的getter和setter方法


工厂模式：

JSON：在企业级项目开发中扮演的角色是无比重要的。
使用fastjson工具包，可以方便的将字符串类型的JSON数据，转换为一个JSONObject对象，然后通过其中的getX()方法，获取指定的字段的值。


J2EE平台在接收用户创建的任务请求后，会将任务信息插入mysql的task表中，任务参数以JSON格式封装在task_param中
接着J2EE平台会执行我们的spark-submit shell脚本，将taskid作为参数传递给spark-submit shell脚本，脚本在执行时，是可以接收参数的，并且会将接受的参数，传递给main函数，参数就封装在main函数的args数组中

进行session粒度的聚合
1.从user_visit_action表中，查询出来指定日期范围内的行为数据，形成RDD
从taskparam中取出startDate 和 endDate
写sql：select * from user_visit_action where date>=startDate and date<=endDate 
sqlContext.sql(sql)形成DataFrame
.javaRDD()形成RDD


接着 将行为数据按照session_id进行groupBykey，此时数据的粒度，就是session粒度，然后将session粒度的数据与用户信息数据进行join，所以获取到的session粒度的数据同时包含了session对应的user的信息
actionRDD中的元素是Row，一行Row就是一行用户访问记录action
将actionRDD映射为<session_id,Row>格式，maptopair算子
return new Tuple2<String,Row>(row.getString(2),row)

new PairFunction<Row, String, Row>()
第一个参数是，输入，第二个，第三个参数是输出

接着对maptopair好的<session_id,Row>进行groupbykey

接着，对每一个session分组进行聚合，将session中所有的搜索词和点击品类都聚合起来
<userid,partAggrInfo(sessionid,searchKeywords,clickCategoryIds)>，userid在前面是因为又进行了一次maptopair

Iterator<Row> iterator = tuple._2.iterator();
对session_id对应的多条数据把他们变成一个iterator对象

不是每一行数据都有searchKeyword，clickCategoryId两个字段有的为null，所以要判断，为null不拼接字符串，.append进建立好的StringBuffer
StringBuilder是线程不安全的，而StringBuffer是线程安全的

完成后返回<sessionid,partAggrInfo>

因为要跟用户信息进行聚合join，key一定是userid才可以<userid,Row>，所以要对<sessionid,partAggrInfo>进行maptopair，但是多此一举，直接返回<userid,partAggrInfo>，跟用户信息join后，再将key设置为sessionid，最后返回的数据格式是<sessionid,fullAggrInfo>


接着，查询所有用户数据，将结果映射为<userid,Row>，应用了maptopair

<userid,partAggrInfo>与<userid,Row> join 然后通过maptopair返回<sessionid,fullAggrInfo>格式的数据

getFieldFromConcatString可以取出field

最后return sessionid2FullAggrInfoRDD;


2.过滤session数据
ParamUtils.getParam取得task的参数
对sessionid2FullAggrInfoRDD应用filter算子
ValidUtils
一次按照条件进行过滤
（startAge、endAge）
（professionals）
（cities）
男/女
按照搜索词进行过滤，判断session搜索词中有任何一个与筛选条件中的搜索词相当，即通过

自定义Accumulator
统计出来之前通过条件过滤的session
访问时长在0s~3s的session的数量，占总session数量的比例
4s~6s
。。。
。。。

一般的方法：
Accumulator 1s_3s = sc.accumulator(0L);
会有很多个Accumulator

对过滤后的session，调用foreach，遍历所有session，计算每个session的访问时长和访问步长
访问时长：把session的最后一个action的time减去session的第一个action的time
访问步长：session的action的数量
计算出访问时长和访问步长以后，根据对应的区间，找到对应的Accumulator，.add(1L);
同时遍历每一个session，可以给总的session数量对应的Accumulator加1
最后用各个区间的session数量，初一总的session数量，就可以计算出各个区间的占比

传统方式，缺点在于Accumulator太多不便于维护
我们自己定义一个Accumulator，一个accumulator维护所有统计逻辑
使用自定义Accumulator，就可以任意实现自己的复杂分布式计算逻辑
分布式的task需要借助于redis维护中间状态，借助zookeeper实现分布式锁
但是，自定义Accumulator可以更方便进行中间状态的维护，不用担心并发和锁的问题

要实现AccumulatorParam<String>
zero，方法，用于数据的初始化，返回一个值，就是初始化中，所有范围区间的数量，都是0，各个范围区间的统计量进行拼接，用key=value|key=value格式进行连接的字符串

addInPlace和addAccumulator方法基本一样
public String addAccumulator(String v1, String v2) {
		return add(v1, v2);
	}  

v1是我们初始化的字符串，v2使我们变量session时，判断出某个session对应的区间，我们要做的是，在v1中找到v2对应的value，累加1，然后再更新会连接串v1里去
实现add方法
1.v1为空则字节返回v2
使用工具类，从v1中，提取对应v2对应的值，并累加1
使用工具类，将v1中，v2对应的值设置为新的累加后的值
return 更新后的字符串

当经过重重过滤之后，session通过用户指定的筛选条件，也就是需要保留的session，就要根据session的访问时长和访问步长，进行统计，根据session对应的范围进行相应的累加计数
sessionAggrStatAccumulator.add(Constants.SESSION_COUNT);  计算需要计数的session
计算访问时长
	if(visitlength){
		Accumulator.add(Constants.XXX)
	}
计算访问步长
	if(steplength){
		Accumulator.add(Constants.XXX)
	}

return filteredSessionid2AggrInfoRDD;



接着将聚合统计的结果写入mysql
计算各个session范围占比，写入mysql
从Accumulator统计串中取值
计算各个访问时长和访问步长的范围
将统计结果封装为Domain对象
调用对应的DAO插入统计结果



2.session随机抽取
每执行一次用户访问session分析模块，都要执行一次session随机抽取模块
我们用session粒度的聚合数据进行运算
将每个session发生的start_time，value是Row，使用countbykey算子可以获取每天每小时的session数量
实现按时间比例抽取算法：根据上面的每天每小时的session数量，及总的session数量，算出占比，乘以要随机抽取的数量，可以计算出，每天每小时要抽取的session数量，从0-每天每小时session数量的范围内，获取指定抽取数量个随机数，作为随机抽取索引

把session粒度的聚合数据进行groupbykey，遍历每天每小时的session，遇到索引就把session抽取出来，直接写入mysql
sessionid2AggrInfoRDD.mapToPair
映射为time2sessionidRDD=(dateHour, aggrInfo)
第一步：
time2sessionidRDD.countByKey();计算出每天每小时的session数量
第二步：
使用按时间比例随机抽取算法， 计算出每天每小时要抽取session的索引
将<yyyy-MM-dd_HH,count>格式的map，转换成<yyyy-MM-dd,<HH,count>>的格式

总共要抽取100个session，先按照天数，进行平分
<date,<hour,(3,5,20,102)>>  
Random random = new Random();


3.遍历每天每小时的session，根据随机索引进行抽取




模块三：广告点击流量实时统计
埋点日志数据通过某种方式写入到分布式消息队列中
日志写入到nginx，flume监控日志文件，将新产生的文写入消息队列，实时程序去kafka中实时拉取数据，对数据进行实时计算和统计
本模块目的在于，PM可以实时掌握公司的各种广告投放效果。

实时，socket做数据源连接kafka


技术方案：
1.实时计算各个batch中的煤炭各个用户对各个广告的点击次数
2.以高性能的方式将每天各个用户对各个广告的点击次数写入mysql（更新）
3.使用filter过滤出每天对某个广告点击超过100次的黑名单用户，写入mysql
4.使用transform操作，对每个batch RDD进行处理，都工台驾到mysql中的黑名单生成RDD进行join，过滤掉batch RDD中的黑名单用户的广告点击行为
5.使用updatestatebykey，实时计算每天各生个城市各广告的点击量，并更新到mysql
6.使用transform结合spark sql统计每天各省份top3热门广告：首先以每天各省各城市个广澳的点击数量数据，作为基础，统计出每天各省份各广告的点击量，然后启动一个异步子线程，使用spark sql动态将数据rdd转化为dataframe，注册为临时表，使用spark sql开窗函数，统计出各个省份top3热门广告，更新到mysql中
7.使用window操作，将最近1小时滑动窗口内的数据，计算出各广告各分钟的点击量，更新到mysql
8.实现实时计算程序的HA
9.对实时计算程序进行性能调优

spark streaming的上下文构建用的是javastreamingcontext

 KafkaUtils.createDirectStream
 基于direct模式，构建针对kafka集群中指定topic的输入DStream
 对原始数据进行处理，把key拼接为date+userid+adid
 把原始数据map为<key,1>形式
 进行reduceByKey，得到每天每个用户对每个广告的点击量
 
 
 以高性能写入mysql
 不要在driver上创建连接对象，Connection对象不支持序列化
 不要为每一条记录创建一个连接对象
 就是不要对rdd.foreach
 要rdd.foreachpartition,在foreachpartition时创建连接对象
 
 一开始用写入mysql，后来写入hbase
 写入mysql方法1.lowB方法，先查询有没有数据，如果没有insert，如果有update，好处在于每个key对应一条记录，坏处在于要先select，再决定insert还是update
 
 稍微好一线每插一条记录，直接插入，但是要给每条记录加时间戳，相当于维护了一个key的多个版本
 
 后来改用hbase，timestamp的多个版本，而且不区分insert和update，同意就是去对某个行间rowkey去做更新
 
 更新好mysql后，
 
 
 计算每天各省的top3的热门广告
 每一个batch rdd，都代表了最新的全量的每天各个省份各个城市各个广告的点击量
<yyyyMMdd_province_city_adid, clickCount> 原始数据
<yyyyMMdd_province_adid, clickCount> 要拿到各省的点击量，扩大维度，对源数据用transform算子，对rdd用maptopair

结果做一次reduceByKey得到，每天各个省份各个广告的点击量
<yyyyMMdd_province_adid, clickCount> 

将这个RDD转换为DataFrame，注册临时表，用spark sql通过开窗函数获取各省份的热门广告。

return RowFactory.create(date,province,adid,clickCount)

StructType schema = DataTypes.createStructType(Arrays.asList

HiveContext sqlContext = new HiveContext(rdd.context());

						DataFrame dailyAdClickCountByProvinceDF = sqlContext.createDataFrame(rowsRDD, schema);


.registerTempTable注册为临时表

开窗函数查询top3

DataFrame.javaRDD注册为RDD
rowsDstream每次都是刷新出来个个省份最热门的top3广告
将其数据批量更新到mysql中


计算每天各广告近1小时滑动窗口内的点击趋势
我们可以看到，每个广告，最近一小时，每分钟的点击量
每支广告的点击趋势

对源数据进行maptopair
把timestamp格式化到分钟级别
(timeMinute + “_” + adid,1L),某天某小时的某分钟，被单击的1次

这时候过来的每个batch rdd，都会被映射为<yyyyMMddHHMM_adid,1L>的格式
每次出来一个新的batch都要获取近1小时内的所有的batch
然后根据key进行reducebykeyandwindow，统一出来近一小时内的各个分钟各个广告的点击次数

这就是1小时滑动窗口的广告点击趋势

每次都可以拿到，最近1小时内，各分钟各广告的点击量

点图、折线图