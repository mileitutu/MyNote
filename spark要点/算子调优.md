1.MapPartition提升Map类操作性能
spark最基本的原则，就是每个task处理一个RDD的partition

mappartitions的优点：
    如果是普通的map，比如一个partition中有1万条数据，那么function要执行和计算1万次
    但是如果使用了mappartition操作，一个task金汇纸行一次function，只要执行一次就可以了，性能高
mappartitions的缺点：
    如果普通的map操作，一次function的执行，就处理一条数据，比如处理了100条数据了，这时内存不够了，就可以将已经处理完成的数据从内存里GC掉
    所以普通map通常不会导致OOM
    但是mappartitions，对于大数据量来说，一个partition，100万条数据，一次传入一个function后，内存可能一下子不够用，有没有办法腾出空间来，就会OOM

什么时候比较适合用mappartitions系列操作？
数据量不是特别大的时候都可以用mappartitions系列操作，在项目中要先去估算一下RDD的数据量，以及每个partition的量，还有自己给executor的内存资源，看一下，内存容纳所有的partition的资源行不行，不行直接放弃


2.fileter之后使用coalesce减少分区数量
默认情况下，经过了filter之后，rdd中的每个partition的数据量可能都不不太一样了，有的partition多很多，有的partition少很多

    造成的问题：
        1.每个partition数据量变少了，但是在后面进行处理的时候，还是要使用原有的数量的task，可能会浪费task资源
        2.每个partition数据量不一样，会导致后面的每个task处理partition时候task要处理的数据量不同，可能产生数据倾斜
        比如一个partition的数据量100，另一个1000，那么在后面的task处理逻辑一样的情况下，不同的task要处理的数据量可能差别达到了9倍甚至10倍，同样也就导致了速度的差别在9-10倍
        这样，就会导致有些task运行速度快，有些task运行速度慢，这就是数据倾斜

    针对以上两个问题：
        1.针对parttion数据量变少，可以对partition进行压缩，减少partition的数量，不必对只有一点数据量的partition还要去启动一个task
        2.针对因为每个partition数据量不同导致的task快慢不均，也是要去压缩partition的数量
    
    如何实现？
    使用coalesce算子
    用于在filter之后，针对每个partition的数据量不同的情况，压缩partition的数量，且让partition的数据量都尽量均匀紧凑，从而便于后面的task性能提升


3.使用foreachpartition优化写数据库性能
    默认的foreach的缺陷：
        1.每条数据都要调用一次function，task为每条数据都要去执行一次function
        2.如果每个数据都要去建立一个数据库连接，那么就要创建100万次数据库连接
    注意数据库连接的创建和销毁都非常消耗性能，虽然使用了数据库连接池，只是创建了固定数量的数据库连接
    还是需要每条数据都往数据库发送一条sql语句
    以上两点非常耗费性能    

    使用foreachpartition算子后的好处
    foreachpartition在生产环境中通常用来写库，一个partition的数据，task处理一次，一条sql处理多组参数，建立一个数据库连接，发送一条sql语句

    但是也有问题，跟mappartitions一样，如果一个partition的数据量太大，也很可能发生OOM

4.使用repartition解决spark sql并行度低的性能问题
    如何设置并行度？
    1.spark.default.parallelism
    2.textfile(,)传入第二个参数，指定partition数量（不常用）

    这个并行度，如果压根儿没有使用 spark sql（dataframe），那么整个application所有的stage的并行度都是设置的那个参数，除非使用coalesce减少过partition数量

    问题在于，spark sql，用spark sql的那个stage的并行度，无法自行指定，spark sql会默认根据hive表对应的hdfs文件的block，自动设置spark sql查询所在的那个stage的并行度，spark.default.parallelism自行指定的并行度只会在没有spark sql的stage中生效

    spark sql 默认情况下，并行度无法设置，sql中有的操作有复杂的逻辑和算法，但是并行度低，造成速度慢，其他stage特别快

    解决办法：
    使用repartition算子，spark sql 这一步的并行度和task数量，肯定是没有办法改变的，但是可以将spark sql查询出来的rdd用repartition算子进行重新分区，这样task就多了，这样就避免了和spark sql绑定在一个stage的算子只能使用少量task的问题

5.reduceByKey本地聚合
reduceByKey，相较于普通的shuffle操作（比如groupbykey）就是会进行本地聚合，对于map端给下个stage创建每个task创建的输出文件中，写数据之前，就会进行本地combiner操作
   
   使用reduceByKey对性能的提升？
        1.在本地聚合后，map端数据量变少，减少磁盘IO，而且减少磁盘空间占用
        2.下一个stage拉取量也减少，减少网络的数据传输的性能消耗
        3.reduce端进行数据缓存的内存占用也变少
        4.reduce端，需要进行聚合的数据量也减少

    什么情况下使用reducebykey？
    1.类似于wordcount，对每个key对应的值，进行某种数据公式或者算法的计算（累加，累乘）
    2.对一些类似于要对每个key进行一些字符串拼接的这种较为复杂的操作。有时不太好实现，但是如果实现出来，对于性能绝对有帮助，只要能对shuffle调优的都是有价值的