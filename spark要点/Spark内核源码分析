1.spark内核架构
application执行时构建出sparkContext对象，sparkcontext构建出DAGScheduler和taskScheduler，taskScheduler构建出来之后，会去联系master，master通过资源调度算法为application分配资源，分配后，master通过worker启动executor，executor启动后，会去向taskscheduler反向注册，这时sparkContext初始化结束，application继续执行，当application执行到action算子时，会向DAGScheduler提交job，DAGScheduler会为job划分stage，为每个stage创建一个taskset，并提交给taskscheduler，taskscheduler会将taskset里的task根据task划分算法，分配到集群里的executor中，executor接收到task之后，会从executor中的线程池里取出一个线程交给taskrunner来运行task。
每个task针对RDD中的一个partition
task有两种，shufflemaptask，和resulttask，只有最后一个stage是resulttask，其他stage都是shufflemaptask


2.宽依赖和窄依赖
窄依赖 narrow dependency：RDD的每个partition仅仅依赖于父RDD中的一个partition
宽依赖 shuffle dependency：每一个父RDD中的partition都可能会传输一部分数据到下一个RDD中的多个partition中

3.基于yarn的两种提交模式
